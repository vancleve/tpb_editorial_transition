---
title: "Word frequency analysis of TPB articles 1970-2012 and 2013-2024"
author: "Jeremy Van Cleve"
format: 
  html:
    self-contained: true
---

# Check Scopus data against OpenAlex and World of Science

## Load in data

```{r}
library(RefManageR)
library(tidyverse)

scopus = ReadBib("tpb_2013-2024_scopus.bib", check = "warn") |> as.data.frame() |> as_tibble()
openalex = ReadBib("tpb_2013-2024_openalex-2024-12-03T01-35-58.bib", check = "warn") |> as.data.frame() |> as_tibble()
wos = ReadBib("tpb_2013-2024_webofscience.bib", check = "warn") |> as.data.frame() |> as_tibble()
```

## Check datasets against each other

## WoS vs Scopus

```{r}
scopus |>
  filter(doi %in% setdiff(str_to_lower(scopus$doi), str_to_lower(wos$doi))) |>
  select(author, volume, year, doi, title)

wos |>
  filter(doi %in% setdiff(str_to_lower(wos$doi), str_to_lower(scopus$doi))) |>
  select(author, volume, year, doi, title)
```
It looks like Scopus is a superset of WoS.

## Scopus vs OpenAlex

```{r}
extra_openalex = openalex |> 
  filter(title != "Editorial Board") |>
  pull(doi) |>
  setdiff(scopus$doi)

openalex |>
  filter(doi %in% extra_openalex) |>
  select(author, volume, year, doi, title)

scopus |>
  filter(doi %in% setdiff(str_to_lower(scopus$doi), str_to_lower(openalex$doi))) |>
  select(author, volume, year, doi, title)
```
Once we remove the "Editorial Board" listings, OpenAlex has one in press article that Scopus doesn't have. However, Scopus has 28 articles that OpenAlex doesn't have. Let's use Scopus and just specify that the search was executed in December 2024.

# Scopus search

The Scopus search was executed on Dec 2nd at 9PM EST using the follow search terms:

![](scopus_search_2013-2024.png)

Now we'll do a little processing. First, convert the notes column to a cites colum.
```{r}
scopus = 
  scopus |> 
  mutate(cites = str_extract(note, regex("Cited *by *: *(\\d+)", ignore_case = TRUE), group = 1))
```

Next, remove the "Erratum" type since its just contains title info about previous articles.
```{r}
scopus = 
  scopus |> 
  filter(type != "Erratum")
```

List the years and volumes that are in these data.
```{r}
scopus |> 
  mutate(year = as.numeric(year), volume = as.numeric(volume)) |>
  distinct(year, volume, number) |> arrange(year, volume, number)
```

# Analysis of titles from 2012—2024

Use `spacyr` and `tidytext` to create word tokens the title and create bigrams from the titles. Use `spacyr` to lemmatize the words to see how that changes the results.

```{r}
library(tidytext)
library(spacyr)
library(gt)

data(stop_words)
spacy_initialize()

one_gram = 
  scopus |>
  #mutate(title = str_replace_all(title, "[-–]", "_")) |>
  unnest_tokens(word, title) |>
  anti_join(stop_words) |> 
  #mutate(word = wordStem(word)) |>
  #mutate(word = hunspell_stem(word)) |>  unnest(word) |>
  count(word, sort = TRUE)
one_gram

two_gram = 
  scopus |>
  #mutate(title = str_replace_all(title, "[-–]", "_")) |>
  unnest_tokens(two_gram, title, token = "ngrams", n = 2) |>
  separate_wider_delim(two_gram, delim = " ", names = c("word1", "word2")) |> 
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) |>
  count(word1, word2, sort = TRUE)
two_gram

scopus_spacy = spacy_parse(scopus$title) |> as_tibble()

one_gram_spacy = scopus_spacy |>
  filter(pos != "PUNCT") |>
  filter(lemma != "-", lemma != "'s") |>
  anti_join(stop_words, by = join_by(lemma == word)) |>
  rename(word = lemma) |>
  count(word, sort = TRUE)
one_gram_spacy

two_gram_spacy = 
  scopus_spacy |>
  mutate(ttoken = if_else(pos == "VERB", token, lemma)) |>
  group_by(doc_id) |>
  summarize(title = (\(x) str_c(x, collapse = " "))(ttoken)) |>
  unnest_tokens(two_gram, title, token = "ngrams", n = 2) |>
  separate_wider_delim(two_gram, delim = " ", names = c("word1", "word2")) |> 
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) |>
  count(word1, word2, sort = TRUE)
two_gram_spacy
```
The results look cleaner with the lemmatized data so we will use that going forward.

Create a printable table with `gt`.

```{r}
cbind(
  one_gram_spacy |>
  rename(n1 = n) |>
  head(n = 20),
  two_gram_spacy |>
  rename(n2 = n) |>
  head(n = 20)) |> 
  as_tibble() |>
  unite("Word pair", word1:word2, sep = " ") |>
  mutate(Rank = row_number()) |>
  select(Rank, word, n1, "Word pair", n2) |>
  rename(Word = word) |>
  gt() |>
  cols_label(n1 = "Number of publications", n2 = "Number of publications") |>
  tab_spanner(label = "Single words", columns = c(Word, n1)) |>
  tab_spanner(label = "Pair of words", columns = c("Word pair", n2)) #|> as_latex() |> as.character() |> cat()

```

Out of curiosity, how many titles have something to do with COVID-19?

```{r}
scopus |> 
  filter(str_detect(title, regex("covid", ignore_case = TRUE)) 
         | str_detect(title, regex("corona", ignore_case = TRUE))
         | str_detect(title, regex("sars", ignore_case = TRUE)))
```

Not many!

# Analysis of titles from 1970—2012

## Scopus data

Scopus search parameters:

![](scopus_search_1970-2012.png)

Read in data and remove erratum article types.

```{r}
scopus_old = ReadBib("tpb_1970-2012_scopus.bib", check = "warn") |> as.data.frame() |> as_tibble()

scopus_old = 
  scopus_old |> 
  filter(type != "Erratum")
```

List the years and volumes that are in these data.

```{r}
scopus_old |> 
  mutate(year = as.numeric(year), volume = as.numeric(volume)) |>
  distinct(year, volume, number) |> arrange(year, volume, number)
```

Create word tokens from titles and lemmatize.

```{r}
one_gram_old = scopus_old |>
  #mutate(title = str_replace_all(title, "[-–]", "_")) |>
  unnest_tokens(word, title) |>
  anti_join(stop_words) |> 
  count(word, sort = TRUE)
one_gram_old

two_gram_old = scopus_old |>
  #mutate(title = str_replace_all(title, "[-–]", "_")) |>
  unnest_tokens(bigram, title, token = "ngrams", n = 2) |>
  separate_wider_delim(bigram, delim = " ", names = c("word1", "word2")) |> 
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) |>
  count(word1, word2, sort = TRUE)
two_gram_old

scopus_old_spacy = spacy_parse(scopus_old$title) |> as_tibble()

one_gram_old_spacy = scopus_old_spacy |>
  filter(pos != "PUNCT") |>
  filter(lemma != "-", lemma != "'s") |>
  anti_join(stop_words, by = join_by(lemma == word)) |>
  rename(word = lemma) |>
  count(word, sort = TRUE)
one_gram_old_spacy

two_gram_old_spacy = 
  scopus_old_spacy |>
  mutate(ttoken = if_else(pos == "VERB", token, lemma)) |>
  group_by(doc_id) |>
  summarize(title = (\(x) str_c(x, collapse = " "))(ttoken)) |>
  unnest_tokens(two_gram, title, token = "ngrams", n = 2) |>
  separate_wider_delim(two_gram, delim = " ", names = c("word1", "word2")) |> 
  filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) |>
  count(word1, word2, sort = TRUE)
two_gram_old_spacy
```

As with the 2013—2024 data, these results look better with the lemmatized words.

Create a printable table.

```{r}
cbind(
  one_gram_old_spacy |>
  rename(n1 = n) |>
  head(n = 40),
  two_gram_old_spacy |>
  rename(n2 = n) |>
  head(n = 40)) |> 
  as_tibble() |>
  unite("Word pair", word1:word2, sep = " ") |>
  mutate(Rank = row_number()) |>
  select(Rank, word, n1, "Word pair", n2) |>
  rename(Word = word) |>
  gt() |>
  cols_label(n1 = "Number of publications", n2 = "Number of publications") |>
  tab_spanner(label = "Single words", columns = c(Word, n1)) |>
  tab_spanner(label = "Pair of words", columns = c("Word pair", n2)) #|> as_latex() |> as.character() |> cat()
```

# Combined tables for 2013—2024 and 1970—2012

## One table

```{r}
cbind(
  one_gram_spacy |>
    left_join(one_gram_old_spacy |> mutate(Rank_old1 = row_number()), 
              by = join_by(word), suffix = c("_new1", "_old1")) |>
    head(n = 20),
  
  two_gram_spacy |>
    unite("Word pair", word1:word2, sep = " ") |>
    left_join(two_gram_old_spacy |> mutate(Rank_old2 = row_number()) |> unite("Word pair", word1:word2, sep = " "), 
              by = join_by("Word pair"), suffix = c("_new2", "_old2")) |>
    head(n = 20)) |>
  as_tibble() |>
  mutate(Rank_new1 = row_number(), Rank_new2 = row_number()) |>
  #select(word, n_new1, n_old1, Rank_new1, Rank_old1, "Word pair", n_new2, n_old2, Rank_new2, Rank_old2) |>
  select(word, n_new1, Rank_new1, Rank_old1, "Word pair", n_new2, Rank_new2, Rank_old2) |>
  gt() |>
  #sub_missing(columns = c(n_old1, Rank_old1, n_old2, Rank_old2), missing_text = "-") |>
  sub_missing(columns = c(Rank_old1, Rank_old2), missing_text = "-") |>
  cols_label(word = "Word",
             n_new1 = "2013—2024", n_new2 = "2013—2024", 
             #n_old1 = "1970—2012", n_old2 = "1970—2012", 
             Rank_new1 = "2013—2024", Rank_new2 = "2013—2024", Rank_old1 = "1970—2012", Rank_old2 = "1970—2012") |>
  #tab_spanner(label = "# of pubs", columns = c(n_new1, n_old1), id = "one_pubs_span") |>
  tab_spanner(label = "# of pubs", columns = c(n_new1), id = "one_pubs_span") |>
  #tab_spanner(label = "# of pubs", columns = c(n_new2, n_old2), id = "two_pubs_span") |>
  tab_spanner(label = "# of pubs", columns = c(n_new2), id = "two_pubs_span") |>
  tab_spanner(label = "Rank", columns = c(Rank_new1, Rank_old1), id = "one_rank_span") |>
  tab_spanner(label = "Rank", columns = c(Rank_new2, Rank_old2), id = "two_rank_span") |>
  tab_spanner(label = "Single words", spanners = c("one_pubs_span", "one_rank_span")) |>
  tab_spanner(label = "Pair of words", spanners = c("two_pubs_span", "two_rank_span")) #|> as_latex() |> as.character() |> cat()
```

## Two tables

```{r}
one_gram_spacy |>
  left_join(one_gram_old_spacy |> mutate(Rank_old1 = row_number()), 
            by = join_by(word), suffix = c("_new1", "_old1")) |>
  head(n = 20) |>
  as_tibble() |>
  mutate(Rank_new1 = row_number()) |>
  select(word, n_new1, Rank_new1, Rank_old1) |>
  gt() |>
  sub_missing(columns = c(Rank_old1), missing_text = "-") |>
  cols_label(word = "Word",
             n_new1 = "2013—2024", Rank_new1 = "2013—2024", Rank_old1 = "1970—2012") |>
  tab_spanner(label = "# of pubs", columns = c(n_new1), id = "one_pubs_span") |>
  tab_spanner(label = "Rank", columns = c(Rank_new1, Rank_old1), id = "one_rank_span") |>
  tab_spanner(label = "Single words", spanners = c("one_pubs_span", "one_rank_span")) #|> as_latex() |> as.character() |> cat()

two_gram_spacy |>
  unite("Word pair", word1:word2, sep = " ") |>
  left_join(two_gram_old_spacy |> mutate(Rank_old2 = row_number()) |> unite("Word pair", word1:word2, sep = " "), 
            by = join_by("Word pair"), suffix = c("_new2", "_old2")) |>
  head(n = 20) |>
  as_tibble() |>
  mutate(Rank_new2 = row_number()) |>
  select("Word pair", n_new2, Rank_new2, Rank_old2) |>
  gt() |>
  sub_missing(columns = c(Rank_old2), missing_text = "-") |>
  cols_label(n_new2 = "2013—2024", Rank_new2 = "2013—2024", Rank_old2 = "1970—2012") |>
  tab_spanner(label = "# of pubs", columns = c(n_new2), id = "two_pubs_span") |>
  tab_spanner(label = "Rank", columns = c(Rank_new2, Rank_old2), id = "two_rank_span") |>
  tab_spanner(label = "Pair of words", spanners = c("two_pubs_span", "two_rank_span")) #|> as_latex() |> as.character() |> cat()
```